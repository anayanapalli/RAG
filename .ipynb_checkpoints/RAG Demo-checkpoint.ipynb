{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import openai\n",
    "import dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "# Set OpenAI API key from environment variable\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for obtaining chat completions using OpenAI's GPT-3.5 Turbo\n",
    "def get_chat_completion(prompt, model=\"gpt-3.5-turbo\", max_tokens=50, api_key=None):\n",
    "    from openai import OpenAI\n",
    "    \n",
    "    try:\n",
    "        # Initialize OpenAI client\n",
    "        client = OpenAI()\n",
    "        \n",
    "        # Generate chat completions based on user prompt\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt,}],\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "        \n",
    "        # Return the content of the response's choices\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        # Handle exceptions and return an error message\n",
    "        return f\"An error occurred: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the PDF file to be processed\n",
    "file_to_read = \"/Users/anayanapalli/Documents/Laika.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use langchain library to load and split the pages of the PDF file\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(file_to_read)\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use langchain library to create embeddings for the document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use langchain library to create a vector store (FAISS) from document pages and embeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "db = FAISS.from_documents(pages, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use langchain library to create a RetrievalQA chain with OpenAI language model and the FAISS retriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import OpenAI\n",
    "llm = OpenAI()\n",
    "chain = RetrievalQA.from_llm(llm=llm, retriever=db.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of questions related to the document\n",
    "questions = [\n",
    "    \"What breed is Laika?\",\n",
    "    \"Does Laika have any friends?\",\n",
    "    \"How did Laika become interested in space?\",\n",
    "    \"Did Laika return from space?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************************************************************************\n",
      "Question: What breed is Laika?\n",
      "GPT-3.5: Laika was a mixed-breed dog, often described as a Siberian Husky or a Siberian Husky mix.\n",
      "RAG :  Laika is a Shiba Inu.\n",
      "*****************************************************************************************************************\n",
      "Question: Does Laika have any friends?\n",
      "GPT-3.5: Laika, the Soviet space dog, does not have any friends in the conventional sense as she was a dog used for scientific purposes. However, she was cared for and trained by her handlers who might have formed a bond with her during her time at\n",
      "RAG :  Yes, Laika has a squirrel sidekick named Rocky and she also meets friendly alien creatures on her space missions.\n",
      "*****************************************************************************************************************\n",
      "Question: How did Laika become interested in space?\n",
      "GPT-3.5: Laika was a stray dog who was found on the streets of Moscow, Soviet Union, in 1957. She was chosen for the space mission primarily because of her size, temperament, and adaptability to the confinement of a spacecraft. Laika\n",
      "RAG :  Laika became interested in space when she found an old telescope and a tattered star map at a mysterious-looking shed and decided to become the first dog to explore outer space.\n",
      "*****************************************************************************************************************\n",
      "Question: Did Laika return from space?\n",
      "GPT-3.5: No, Laika did not return from space. She was the first living creature to be launched into orbit aboard the Soviet spacecraft Sputnik 2 in 1957. Unfortunately, the mission was one-way, and Laika passed away a few\n",
      "RAG :  Yes, Laika returned from space.\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the list of questions, generate responses using GPT-3.5 Turbo and RetrievalQA model, and print the results\n",
    "for question in questions:\n",
    "    print(\"*\" * 113)\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"GPT-3.5: {get_chat_completion(question, 50)}\")\n",
    "    print(f\"RAG : {chain(question, return_only_outputs=True)['result']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
